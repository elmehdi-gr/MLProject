\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{subcaption}

\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

\title{\textbf{Human Activity Recognition (HAR) using Machine Learning and Deep Learning}}
\author{Ali Ahmed \\ Machine Learning Course \\[0.5cm] \textbf{Supervised by:} \\ Professor Fahd Kalloubi}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This project explores the development of Human Activity Recognition (HAR) systems using wearable Inertial Measurement Unit (IMU) sensor data. We implemented a complete end-to-end machine learning pipeline, starting from raw sensor data exploration and preprocessing to advanced feature engineering and dimensionality reduction. We evaluated both unsupervised clustering techniques (K-Means, DBSCAN) and supervised learning algorithms (Logistic Regression, Random Forest, SVM, Gradient Boosting). Furthermore, we explored Deep Learning approaches using Multi-Layer Perceptrons (MLP) and 1D Convolutional Neural Networks (CNNs). Our experiments, tracked via MLflow, demonstrate that supervised ensemble methods like Gradient Boosting and Random Forest achieve superior performance with an accuracy of over 97\%, comparable to deep learning models, making them highly effective for activity classification tasks.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}
Human Activity Recognition (HAR) is a crucial field in machine learning with applications in healthcare, elderly monitoring, sports analytics, and human-computer interaction. The objective is to classify human movements (e.g., walking, sitting, standing) based on time-series data collected from sensors like accelerometers and gyroscopes.

In this project, we utilize a dataset collected from 67 subjects wearing IMU sensors on their chest, hands, and knees. The dataset includes six core activities:
\begin{itemize}
    \item Standing
    \item Walking
    \item Sitting
    \item Lying Down
    \item Going Upstairs
    \item Going Downstairs
\end{itemize}

Our goal is to build robust classification models that can accurately identify these activities from unseen sensor data.

\section{Methodology}

\subsection{Data Exploration and Preprocessing}
We began by analyzing the dataset structure, which consists of synchronized recordings of quaternions, acceleration, and angular velocity. 
\begin{itemize}
    \item \textbf{Data Cleaning:} We handled missing values and infinite numbers by replacing them with zeros or interpolating where appropriate.
    \item \textbf{Exploratory Data Analysis (EDA):} We visualized class distributions to check for imbalance and plotted raw sensor signals to understand the temporal nature of the activities. Correlation heatmaps were generated to identify redundant features.
\end{itemize}

\subsection{Feature Engineering}
Raw time-series data is high-dimensional and noisy. To improve model performance, we engaged in extensive feature engineering:
\begin{itemize}
    \item \textbf{Statistical Features:} Mean, standard deviation, min, max, and percentiles were calculated for windowed signal segments.
    \item \textbf{Frequency Domain Features:} Fast Fourier Transform (FFT) was used to extract spectral energy and dominant frequencies, which are critical for distinguishing rhythmic activities like walking from static ones like sitting.
\end{itemize}

\subsection{Dimensionality Reduction}
To visualize the high-dimensional feature space and reduce computational cost, we applied:
\begin{itemize}
    \item \textbf{PCA (Principal Component Analysis):} Reduced the feature space while retaining 95\% of the variance.
    \item \textbf{t-SNE (t-Distributed Stochastic Neighbor Embedding):} Used for 2D visualization, showing clear separation between static activities (Sitting, Lying) and dynamic ones (Walking, Stairs).
\end{itemize}

\section{Experiments}

\subsection{Unsupervised Learning}
We first applied unsupervised methods to see if natural clusters corresponded to activity labels.
\begin{itemize}
    \item \textbf{K-Means Clustering:} Tested with $K=6$. While it separated static and dynamic groups well, it struggled to distinguish fine-grained classes like "Going Upstairs" vs. "Walking".
    \item \textbf{DBSCAN:} Used for density-based clustering, primarily to detect outliers/anomalies in the dataset.
\end{itemize}

\subsection{Supervised Learning}
We trained four classical machine learning classifiers using a 5-fold stratified cross-validation strategy to ensure robustness.
\begin{enumerate}
    \item \textbf{Logistic Regression:} A computed baseline model.
    \item \textbf{Random Forest (RF):} An ensemble of decision trees, robust to overfitting.
    \item \textbf{Support Vector Machine (SVM):} Effective for high-dimensional margins.
    \item \textbf{Gradient Boosting Classifier (GBT):} A powerful boosting method that builds trees sequentially.
\end{enumerate}

\subsection{Neural Networks}
We advanced to Deep Learning models using PyTorch:
\begin{itemize}
    \item \textbf{MLP (Multi-Layer Perceptron):} Trained on the engineered feature set.
    \item \textbf{1D CNN (Convolutional Neural Network):} Trained directly on raw time-series data windows, allowing the model to learn spatial-temporal features automatically without manual feature engineering.
\end{itemize}

\subsection{Experiment Tracking with MLflow}
All experiments were tracked using \textbf{MLflow}. We logged:
\begin{itemize}
    \item Hyperparameters (learning rates, tree depths, estimators).
    \item Metrics (Accuracy, F1-Score, Training Time).
    \item Artifacts (Confusion Matrices, Loss Curves).
\end{itemize}
This ensured full reproducibility and facilitated easy comparison of model performance.

\section{Results and Discussion}

The performance of the supervised models on the test set is summarized below:

\begin{table}[h]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Model} & \textbf{Test Accuracy} & \textbf{F1-Score (Weighted)} & \textbf{Training Time (s)} \\ \midrule
Logistic Regression & 85.33\% & 0.8435 & $\sim$19.0 \\
SVM (RBF Kernel) & 88.48\% & 0.8845 & $\sim$31.7 \\
\textbf{Random Forest} & \textbf{97.06\%} & \textbf{0.9706} & \textbf{$\sim$22.7} \\
\textbf{Gradient Boosting} & \textbf{97.12\%} & \textbf{0.9711} & \textbf{$\sim$23.6} \\ \bottomrule
\end{tabular}
\caption{Performance Comparison of Supervised Models}
\label{tab:results}
\end{table}

\subsection{Key Findings}
\begin{itemize}
    \item \textbf{Ensemble Dominance:} Gradient Boosting and Random Forest significantly outperformed linear models and SVM, achieving over 97\% accuracy. They effectively handled the non-linear relationships in sensor data.
    \item \textbf{Feature Engineering:} The custom features extracted (Statistical + FFT) played a vital role in the success of classical ML models.
    \item \textbf{Neural Networks:} The 1D CNN showed promising results on raw data, proving that deep learning can bypass manual feature extraction, though at the cost of higher training time and computational resources.
\end{itemize}

\section{Conclusion}
In this project, we successfully developed a high-performing Human Activity Recognition system. We verified that while deep learning (1D CNN) offers powerful automated feature extraction, classical ensemble methods like \textbf{Gradient Boosting}, when combined with expert feature engineering, provide state-of-the-art accuracy with significantly lower computational overhead.

The full experimental pipeline, tracked via MLflow, ensures that our results are reproducible and scalable for future research or real-time deployment on edge devices.

\end{document}
